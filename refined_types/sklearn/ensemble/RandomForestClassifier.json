{
    "sklearn.ensemble.RandomForestClassifier": {
        "criterion": {
            "type":{
                "kind":"EnumType",
                "types":[
                    {
                        "kind":"EnumType",
                        "name":"gini"
                    },
                    {
                        "kind":"EnumType",
                        "name":"entropy"
                    }
                ]
            },
            "docstring":{
                "type":"{“gini”, “entropy”}, default=”gini”",
                "description":"The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n\n"
            }
        },
        "max_features": {
            "type":{
                "kind":"UnionType",
                "types":[
                    {
                        "kind":"EnumType",
                        "name":"auto"
                    },
                    {
                        "kind":"EnumType",
                        "name":"sqrt"
                    },
                    {
                        "kind":"EnumType",
                        "name": "log2"
                    },
                    {
                        "kind": "NamedType",
                        "name": "float"
                    },
                    {
                        "kind": "NamedType",
                        "name": "int"
                    }
                ]
            },
            "docstring":{
                "type":"{“auto”, “sqrt”, “log2”}, int or float, default=”auto”",
                "description":"The number of features to consider when looking for the best split:\n\nIf int, then consider max_features features at each split.\n\nIf float, then max_features is a fraction and round(max_features * n_features) features are considered at each split.\n\nIf “auto”, then max_features=sqrt(n_features).\n\nIf “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n\nIf “log2”, then max_features=log2(n_features).\n\nIf None, then max_features=n_features.\n\nNote: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features."
            }
        },
        "class_weight": {
            "type":{
                "kind":"UnionType",
                "types":[
                    {
                        "kind":"EnumType",
                        "name":"balanced"
                    },
                    {
                        "kind":"EnumType",
                        "name":"balanced_subsample"
                    },
                    {
                        "kind": "NamedType",
                        "name": "dict"
                    },
                    {
                        "kind": "NamedType",
                        "name": "list"
                    }
                ]
            },
            "docstring":{
                "type":"{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None",
                "description":"Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.\n\nNote that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].\n\nThe “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n\nThe “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.\n\nFor multi-output, the weights of each column of y will be multiplied.\n\nNote that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified."
            }
        },
        "ccp_alpha": {
            "type":{
                "kind": "BoundaryType",
                "baseType": "float",
                "min": 0,
                "minInclusive": true,
                "max": null,
                "maxInclusive": false
            },
            "docstring":{
                "type":"non-negative float, default=0.0",
                "description":"Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed."
            }
        },
        "max_samples": {
            "type":{
                "kind":"UnionType",
                "types":[
                    {
                        "kind":"NamedType",
                        "name":"int"
                    },
                    {
                        "kind":"BoundaryType",
                        "baseType": "float",
                        "min": 0,
                        "minInclusive": false,
                        "max": 1,
                        "maxInclusive": true
                    }
                ]
            },
            "docstring":{
                "type":"int or float, default=None",
                "description":"If float, then draw `max_samples * X.shape[0]` samples. Thus, `max_samples` should be in the interval `(0.0, 1.0]`."
            }
        }
    }
}
